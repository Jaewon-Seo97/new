{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "declared-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D, concatenate, Activation,Conv2DTranspose\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, History, ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "economic-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = K.epsilon()\n",
    "gamma = 5\n",
    "alpha = 0.6\n",
    "beta = 0.6\n",
    "\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1))\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "    \n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1))\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn) \n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=0.001):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1,2,3])\n",
    "    union = K.sum(y_true,[1,2,3])+K.sum(y_pred,[1,2,3])-intersection\n",
    "    iou = K.mean((intersection + smooth) / (union + smooth), axis=0)\n",
    "    return iou\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "get_custom_objects().update({\n",
    "    \n",
    "    'precision' : precision,\n",
    "    'recall' : recall,\n",
    "    'dice_coef' : dice_coef,\n",
    "    'iou_coef' : iou_coef,\n",
    "    'dice_coef_loss' : dice_coef_loss,\n",
    "        \n",
    "})\n",
    "\n",
    "img_size = 512\n",
    "depth = 4\n",
    "filter_sn = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "metric-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((img_size, img_size,1), dtype='float32')\n",
    "\n",
    "def encoder_unet(inputs, filters, kernel_size= 3):\n",
    "    conv = Conv2D(filters, kernel_size, activation=None, padding='same')(inputs)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(filters, kernel_size, activation=None, padding='same')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "#     pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "    \n",
    "    return conv\n",
    "\n",
    "def decoder_unet(inputs, filters, kernel_size= 3, concate_num=depth-1):\n",
    "    up = concatenate([Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(inputs), encoders[concate_num]], axis=3)\n",
    "    conv = Conv2D(filters, kernel_size, activation=None, padding='same')(up)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(filters, kernel_size, activation=None, padding='same')(conv)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    \n",
    "    return conv\n",
    "\n",
    "def unet(depth=4, filter_sn=32, img_size=512):\n",
    "    global encoders\n",
    "    encoders=[]\n",
    "    \n",
    "    inputs = Input((img_size, img_size,1), dtype='float32')\n",
    "    for down in range(0,depth+1):\n",
    "        print(down)\n",
    "        if down == 0:\n",
    "            encoder_conv = encoder_unet(inputs, filters=filter_sn, kernel_size= 3)\n",
    "            encoders.append(encoder_conv)\n",
    "            encoder_conv = MaxPooling2D(pool_size=(2, 2))(encoder_conv)\n",
    "#             print(filter_sn)\n",
    "        elif down>0 and down<depth:\n",
    "            encoder_conv = encoder_unet(encoder_conv, filters=filter_sn*(2**down), kernel_size= 3)\n",
    "            encoders.append(encoder_conv)\n",
    "            encoder_conv = MaxPooling2D(pool_size=(2, 2))(encoder_conv)\n",
    "            print(filter_sn*(2**down))\n",
    "        else:\n",
    "            encoder_conv = encoder_unet(encoder_conv, filters=filter_sn*(2**(down-1)), kernel_size= 3)\n",
    "#             encoders.append(encoder_conv)\n",
    "            print(filter_sn*(2**(down-1)))\n",
    "            print(encoder_conv.shape)\n",
    "    \n",
    "\n",
    "#         print(filter_sn*(2**depth))\n",
    "        \n",
    "    for up in range(0,depth):\n",
    "        if up == 0:\n",
    "            decoder_conv= decoder_unet(encoder_conv, filters=filter_sn*(2**(down-1)), kernel_size= 3, concate_num=len(encoders)-1)\n",
    "        else:\n",
    "            decoder_conv= decoder_unet(decoder_conv, filters=filter_sn*(2**(depth-up-1)),kernel_size= 3, concate_num=depth-up-1)\n",
    "        print('decoders:', decoder_conv.shape)\n",
    "    last_conv = Conv2D(1, (1, 1), activation='sigmoid')(decoder_conv)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=last_conv) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "viral-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "64\n",
      "2\n",
      "128\n",
      "3\n",
      "256\n",
      "4\n",
      "256\n",
      "(?, 32, 32, 256)\n",
      "decoders: (?, 64, 64, 256)\n",
      "decoders: (?, 128, 128, 128)\n",
      "decoders: (?, 256, 256, 64)\n",
      "decoders: (?, 512, 512, 32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 512, 512, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 32) 320         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 32) 9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512, 512, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 32) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 64) 36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256, 256, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 64) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 128 147584      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 128 512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 128, 128 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 128)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 256)  590080      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 256)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 256)  590080      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 256)  262400      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 256)  590080      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 128 131200      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 128 512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 128 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 128 147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 128 512         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 128 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 64) 32832       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 64) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 64) 36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256, 256, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256, 256, 64) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 512, 512, 32) 8224        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512, 512, 64) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 512, 512, 32) 18464       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 512, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 512, 512, 32) 9248        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 512, 512, 32) 128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 512, 512, 32) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 512, 512, 1)  33          activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 5,147,297\n",
      "Trainable params: 5,142,433\n",
      "Non-trainable params: 4,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=unet(depth=4, filter_sn=32, img_size=512)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading data\")\n",
    "\n",
    "train_image = np.load('../data/img200/npy/train_'+str(img_size)+'.npy')\n",
    "train_label = np.load('../data/img200/npy/label_'+str(img_size)+'.npy')\n",
    "test_image =np.load('../data/img200/npy/test_'+str(img_size)+'.npy')\n",
    "# test_label = np.load('../data/npytest/test_label_512.npy')\n",
    "test_label = np.load('../data/img200/npy/test_label_'+str(img_size)+'.npy')\n",
    "\n",
    "\n",
    "train_image = train_image/255\n",
    "train_label = train_label/255\n",
    "test_image = test_image/255\n",
    "test_label = test_label/255\n",
    "\n",
    "print(\"loading data done\")\n",
    "print(train_image.shape)\n",
    "print(train_label.shape)\n",
    "print(test_image.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alone-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001), loss=dice_coef_loss, metrics=['accuracy', recall, precision, dice_coef])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1, min_delta=1e-4)\n",
    "earlystopper = EarlyStopping(monitor='val_loss',patience=30, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint('./result/model_seg_'+str(depth)+'.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n",
    "\n",
    "callbacks_list = [reduce_lr, model_checkpoint, earlystopper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(train_image, train_label, batch_size=5, epochs=100, verbose=1,validation_split=0.2, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_image, batch_size=5, verbose=1)\n",
    "np.save('../data/img200/pred/test5_pred_'+str(img_size)+'.npy', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_Thresh(preds_test,Thresh_value):\n",
    "    \n",
    "    preds_mask = np.ndarray((len(test_label),img_size, img_size, 1), dtype=np.float32)\n",
    "  \n",
    "    preds_mask0 = preds_test[:,:,:,0] > Thresh_value\n",
    "  \n",
    "    preds_mask[:,:,:,0] = preds_mask0*1\n",
    "    \n",
    "    return preds_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "_loss, _acc, _precision, _recall,_dice_coef = model.evaluate(test_image, test_label, batch_size=5, verbose=1)\n",
    "print('loss: {:.3f}, accuracy: {:.3f}, precision: {:.3f}, recall: {:.3f}, dice_coef:{:.3f}'.format(_loss, _acc*100, _precision*100, _recall*100, _dice_coef*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_mask = preds_Thresh(predict,0.5)\n",
    "check_len = 5\n",
    "for toto in range(check_len):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(test_image[toto,:,:,0],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(test_label[toto,:,:,0],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(test_image[toto,:,:,0],cmap='gray')\n",
    "    plt.imshow(test_label[toto,:,:,0],cmap='Reds' ,alpha=0.6)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(test_image[toto,:,:,0],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(preds_mask[toto,:,:,0],cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(test_image[toto,:,:,0],cmap='gray')\n",
    "    plt.imshow(preds_mask[toto,:,:,0],cmap='Reds' ,alpha=0.6)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test_label_ravel = np.ravel(test_label) ###image convert to vector\n",
    "image_test_label_ravel_cur = image_test_label_ravel.astype(np.bool)\n",
    "\n",
    "predic_ravel_1 = np.ravel(model.predict(test_image, batch_size=10))\n",
    "predic_ravel_1 = predic_ravel_1.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_1, recall_1, thresholds_1 = precision_recall_curve(image_test_label_ravel_cur, predic_ravel_1)\n",
    "average_precision_score_1 = average_precision_score(image_test_label_ravel_cur, predic_ravel_1)*100\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))        \n",
    "plt.title('Precision Recall Curve',fontsize=20)\n",
    "plt.xlabel('Recall',fontsize=15)\n",
    "plt.ylabel('Precision',fontsize=15)\n",
    "\n",
    "plt.plot(recall_1, precision_1, label='Dice_coeff = %0.2f, AP = %0.2f'% (_dice_coef, average_precision_score_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
